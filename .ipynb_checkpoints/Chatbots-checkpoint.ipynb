{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Question & Answer Bot Project\n",
    "\n",
    "## Project Overview\n",
    "In this project, we implement a chatbot that can answer questions based on a \"story\" given to the bot.\n",
    "\n",
    "We are using a subset of the BaBi dataset released by Facebook research. https://research.fb.com/downloads/babi.\n",
    "There are 10,000 data in the training set and 1,000 data in the testing set. Each data in the training/testing set consists of 3 components:\n",
    "> - Story - consists of single or multiple sentences\n",
    "> - Question - single sentence query related to the story\n",
    "> - Answer - \"yes\" or \"no\" answer to the question\n",
    "\n",
    "The model for our chatbot is a RNN network with attention mechanism. It includes the following layers: Embedding, LSTM, Dropout, Dense and Activation. The design of the model pretty much follows the idea in the paper \"End-to-End Memory Networks\": https://arxiv.org/pdf/1503.08895.pdf. \n",
    "\n",
    "Our model achieved pretty high accuary on training/testing set and performs really good on run time generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read as binary\n",
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read as binary\n",
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train data:  10000\n",
      "Length of the test data:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the train data: \", len(train_data))\n",
    "print(\"Length of the test data: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       "  'no'),\n",
       " (['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'hallway',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bathroom', '?'],\n",
       "  'no')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train_data is a list of tuples consist of 3 parts: story, question, answer.\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'journeyed',\n",
       " 'moved',\n",
       " 'the',\n",
       " 'to'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from all stories and questions\n",
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual length of the vocabulary:  37\n"
     ]
    }
   ],
   "source": [
    "# Add one to length of vocabulary: Keras embedding layer requires this.\n",
    "vocab_len = len(vocab) + 1\n",
    "print(\"Actual length of the vocabulary: \", vocab_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of all the stories\n",
    "all_story_len = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximum of the stories\n",
    "max_story_len = max(all_story_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of the stories:  156\n",
      "Maximum length of the question:  6\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum length of the stories: \", max_story_len)\n",
    "print(\"Maximum length of the question: \", max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'milk': 1,\n",
       " 'down': 2,\n",
       " 'discarded': 3,\n",
       " '?': 4,\n",
       " 'is': 5,\n",
       " 'bedroom': 6,\n",
       " 'took': 7,\n",
       " 'bathroom': 8,\n",
       " 'put': 9,\n",
       " 'there': 10,\n",
       " 'grabbed': 11,\n",
       " 'left': 12,\n",
       " 'apple': 13,\n",
       " 'up': 14,\n",
       " 'the': 15,\n",
       " 'daniel': 16,\n",
       " 'journeyed': 17,\n",
       " '.': 18,\n",
       " 'to': 19,\n",
       " 'football': 20,\n",
       " 'office': 21,\n",
       " 'picked': 22,\n",
       " 'went': 23,\n",
       " 'back': 24,\n",
       " 'garden': 25,\n",
       " 'kitchen': 26,\n",
       " 'john': 27,\n",
       " 'no': 28,\n",
       " 'in': 29,\n",
       " 'mary': 30,\n",
       " 'sandra': 31,\n",
       " 'dropped': 32,\n",
       " 'hallway': 33,\n",
       " 'yes': 34,\n",
       " 'got': 35,\n",
       " 'travelled': 36,\n",
       " 'moved': 37}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train_story_text is a list of lists of words\n",
    "train_story_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_story_seq))\n",
    "print(len(train_story_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[30, 37, 19, 15, 8, 18, 31, 17, 19, 15, 6, 18],\n",
       " [30,\n",
       "  37,\n",
       "  19,\n",
       "  15,\n",
       "  8,\n",
       "  18,\n",
       "  31,\n",
       "  17,\n",
       "  19,\n",
       "  15,\n",
       "  6,\n",
       "  18,\n",
       "  30,\n",
       "  23,\n",
       "  24,\n",
       "  19,\n",
       "  15,\n",
       "  6,\n",
       "  18,\n",
       "  16,\n",
       "  23,\n",
       "  24,\n",
       "  19,\n",
       "  15,\n",
       "  33,\n",
       "  18]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own list of list of word indicies with padding.\n",
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len, max_question_len=max_question_len):\n",
    "    # Stories = X\n",
    "    X = []\n",
    "    \n",
    "    # Questions = Xq\n",
    "    Xq = []\n",
    "    \n",
    "    # Y Correct Answer ['yes', 'no']\n",
    "    Y = []\n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # for each story\n",
    "        # [23, 14, 15]\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)   # X holds list of lists of word indices for stories.\n",
    "        Xq.append(xq) # Xq holds list of lists for word indices for questions.\n",
    "        Y.append(y) # Y holds lists of lists of (38) biniary numbers, only 1 of them is 1.\n",
    "        \n",
    "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 15,  6, 18],\n",
       "       [ 0,  0,  0, ..., 15, 25, 18],\n",
       "       [ 0,  0,  0, ..., 15, 25, 18],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 15, 13, 18],\n",
       "       [ 0,  0,  0, ..., 15, 25, 18],\n",
       "       [ 0,  0,  0, ..., 13, 10, 18]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,\n",
       "         0., 497.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 497 of the questions have answer 'yes', 503 of the questions have answer 'no'.\n",
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques\n",
    "\n",
    "The design in this project follows the paper \"End-to-End Memory Networks\" https://arxiv.org/pdf/1503.08895.pdf\n",
    "\n",
    "Below are the detail descriptions about the algorithms and techniques used in this model (quoted from that paper):\n",
    "\n",
    "**Single Layer:**\n",
    "<img src=\"images/end_to_end_networks_descriptions.GIF\" style=\"width:500;height:500px;\">\n",
    "\n",
    "<img src=\"images/end_to_end_networks_diagram3.GIF\" style=\"width:500;height:500px;\">\n",
    "\n",
    "Source of the above figure: https://arxiv.org/pdf/1503.08895.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of the model\n",
    "\n",
    "The architecture of the model implemented below follows the paper: The https://arxiv.org/pdf/1503.08895.pdf\n",
    "\n",
    "The layers of the model looks like:\n",
    "1. Input\n",
    "> - A. input_sequence (fits on input_train): shape = (batch_size, max_story_len))\n",
    "> - B. question (fits on queries_train: shape = (batch_size, max_query_len))\n",
    "2. Embedding\n",
    "> - A. embedding for input_encoder_m: take input from input_sequence. Output shape: (batch_size, story_maxlen, embedding_dim)\n",
    "> - B. embedding for input_encoder_c: take input from input_sequence. Output shape: (batch_size, story_maxlen, max_question_len)\n",
    "> - C. embedding for question_encoder: take input from question. Output shape: (batch_size, query_maxlen, embedding_dim)\n",
    "3. Layers after Embedding\n",
    "> - A. dot: dot input_encoded_m and question_encoded (output from 2A and 2C) along axes of embedding dimension. Output shape: (batch_size, story_maxlen, query_maxlen)\n",
    "> - B. add: add output from 3A and 2B. Output shape: (batch_size, story_maxlen, query_maxlen)\n",
    "> - C. Permute: permute 2nd and 3rd axes from output of 3B. Output shape: (batch_size, query_maxlen, story_maxlen)\n",
    "> - D. concatenate: concatenate output from 3C and 2B. Output shape: (batch_size, query_maxlen, story_maxlen+embedding_dim) \n",
    "4. LSTM (hidden_unit = 32)\n",
    "5. Dropout (rate = 0.3)\n",
    "6. Dense (output = vocab_size)\n",
    "7. Activation (activation function = 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER shape=(max_story_len, batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_len\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\flasi\\anaconda3\\envs\\igti\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODED <---- ENCODER(INPUT)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "# input_encoded_m: (batch_size, story_maxlen, embedding_dim)\n",
    "# input_encoded_c: (batch_size, story_maxlen, query_maxlen)\n",
    "# question_encoded: (batch_size, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 156, 64)\n",
      "(?, 6, 64)\n"
     ]
    }
   ],
   "source": [
    "print(input_encoded_m.shape)\n",
    "print(question_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes=(2,2)) # why axes is (2,2) ==> dot product along the embedding dim (64 numbers dot 64 numbers)\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "# NOTE: match after dot: (batch_size, story_maxlen, query_maxlen)\n",
    "# match after Activation: (batch_size, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: match (after dot): (batch_size, story_maxlen, query_maxlen)!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c]) # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2,1))(response) # (samples, query_maxlen, story_maxlen)\n",
    "\n",
    "# response after add: (batch_size, story_maxlen, query_maxlen)\n",
    "# response after Permute: (batch_size, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: response after Permute: (batch_size, query_maxlen, story_maxlen)!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "# Note: answer: (batch_size, query_maxlen, story_maxlen+embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer\n",
    "# Note: answer: (batch_size, query_maxlen, story_maxlen+embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: answer (after concatenate): (batch_size, query_maxlen, story_maxlen+embedding_dim)!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer) #(samples, 32)\n",
    "# answer: (batch_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32)\n"
     ]
    }
   ],
   "source": [
    "print(answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "# answer: (batch_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dense(vocab_size)(answer) # (samples, vocab_size) # YES/NO 0000\n",
    "# answer (batch_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)\n",
    "# answer: (batch_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Softmax:0' shape=(?, 38) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\flasi\\anaconda3\\envs\\igti\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 7s 696us/step - loss: 0.9829 - accuracy: 0.4885 - val_loss: 0.7008 - val_accuracy: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.7122 - accuracy: 0.5036 - val_loss: 0.6967 - val_accuracy: 0.4970\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 5s 549us/step - loss: 0.7024 - accuracy: 0.4932 - val_loss: 0.6959 - val_accuracy: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.6988 - accuracy: 0.4934 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 5s 547us/step - loss: 0.6984 - accuracy: 0.4886 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 0.6973 - accuracy: 0.4959 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 0.6964 - accuracy: 0.4970 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.6961 - accuracy: 0.5030 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.6954 - accuracy: 0.5046 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.6961 - accuracy: 0.5027 - val_loss: 0.6954 - val_accuracy: 0.4970\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 6s 577us/step - loss: 0.6950 - accuracy: 0.5073 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.6961 - accuracy: 0.4950 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 6s 580us/step - loss: 0.6957 - accuracy: 0.4979 - val_loss: 0.6963 - val_accuracy: 0.4970\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.6953 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 6s 582us/step - loss: 0.6947 - accuracy: 0.5030 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 6s 575us/step - loss: 0.6954 - accuracy: 0.4985 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 6s 604us/step - loss: 0.6959 - accuracy: 0.4974 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 6s 576us/step - loss: 0.6948 - accuracy: 0.5049 - val_loss: 0.6964 - val_accuracy: 0.4970\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 6s 581us/step - loss: 0.6960 - accuracy: 0.4975 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 6s 581us/step - loss: 0.6944 - accuracy: 0.5022 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.6959 - accuracy: 0.4941 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 6s 587us/step - loss: 0.6945 - accuracy: 0.5016 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 6s 576us/step - loss: 0.6950 - accuracy: 0.5014 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 6s 575us/step - loss: 0.6944 - accuracy: 0.4985 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 6s 587us/step - loss: 0.6946 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.6946 - accuracy: 0.5012 - val_loss: 0.6948 - val_accuracy: 0.5030\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.6941 - accuracy: 0.5015 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 6s 593us/step - loss: 0.6612 - accuracy: 0.6068 - val_loss: 0.6302 - val_accuracy: 0.6610\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.6213 - accuracy: 0.6677 - val_loss: 0.6068 - val_accuracy: 0.6810\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 6s 597us/step - loss: 0.6054 - accuracy: 0.6841 - val_loss: 0.5859 - val_accuracy: 0.6950\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 6s 591us/step - loss: 0.5796 - accuracy: 0.6983 - val_loss: 0.5814 - val_accuracy: 0.7050\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.5631 - accuracy: 0.7096 - val_loss: 0.5590 - val_accuracy: 0.7150\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 6s 589us/step - loss: 0.5425 - accuracy: 0.7260 - val_loss: 0.5588 - val_accuracy: 0.7190\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.5220 - accuracy: 0.7392 - val_loss: 0.5406 - val_accuracy: 0.7270\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.5152 - accuracy: 0.7383 - val_loss: 0.5208 - val_accuracy: 0.7330\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 6s 595us/step - loss: 0.4995 - accuracy: 0.7497 - val_loss: 0.5245 - val_accuracy: 0.7210\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 6s 628us/step - loss: 0.4997 - accuracy: 0.7487 - val_loss: 0.5159 - val_accuracy: 0.7340\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 6s 600us/step - loss: 0.4903 - accuracy: 0.7549 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.4843 - accuracy: 0.7570 - val_loss: 0.5201 - val_accuracy: 0.7270\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.4807 - accuracy: 0.7618 - val_loss: 0.5113 - val_accuracy: 0.7270\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 6s 623us/step - loss: 0.4757 - accuracy: 0.7553 - val_loss: 0.5047 - val_accuracy: 0.7380\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.4699 - accuracy: 0.7667 - val_loss: 0.4958 - val_accuracy: 0.7470\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 6s 624us/step - loss: 0.4658 - accuracy: 0.7735 - val_loss: 0.4933 - val_accuracy: 0.7530\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 7s 678us/step - loss: 0.4605 - accuracy: 0.7785 - val_loss: 0.4831 - val_accuracy: 0.7600\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.4513 - accuracy: 0.7852 - val_loss: 0.4707 - val_accuracy: 0.7690\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.4346 - accuracy: 0.7937 - val_loss: 0.4629 - val_accuracy: 0.7790\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 6s 618us/step - loss: 0.4295 - accuracy: 0.7990 - val_loss: 0.4591 - val_accuracy: 0.7900\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 6s 611us/step - loss: 0.4258 - accuracy: 0.7988 - val_loss: 0.4537 - val_accuracy: 0.7860\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 6s 607us/step - loss: 0.4131 - accuracy: 0.8080 - val_loss: 0.4498 - val_accuracy: 0.7930\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 6s 618us/step - loss: 0.4153 - accuracy: 0.8069 - val_loss: 0.4335 - val_accuracy: 0.7980\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 6s 627us/step - loss: 0.4029 - accuracy: 0.8127 - val_loss: 0.4336 - val_accuracy: 0.7930\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 6s 627us/step - loss: 0.4024 - accuracy: 0.8188 - val_loss: 0.4328 - val_accuracy: 0.7940\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 6s 616us/step - loss: 0.3941 - accuracy: 0.8202 - val_loss: 0.4419 - val_accuracy: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.3929 - accuracy: 0.8232 - val_loss: 0.4332 - val_accuracy: 0.7990\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 0.3876 - accuracy: 0.8240 - val_loss: 0.4327 - val_accuracy: 0.8100\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.3777 - accuracy: 0.8348 - val_loss: 0.4490 - val_accuracy: 0.8010\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.3757 - accuracy: 0.8270 - val_loss: 0.4435 - val_accuracy: 0.7940\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.3731 - accuracy: 0.8350 - val_loss: 0.4279 - val_accuracy: 0.8100\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 7s 741us/step - loss: 0.3671 - accuracy: 0.8365 - val_loss: 0.4291 - val_accuracy: 0.8110\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 6s 605us/step - loss: 0.3658 - accuracy: 0.8343 - val_loss: 0.4472 - val_accuracy: 0.8010\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.3677 - accuracy: 0.8347 - val_loss: 0.4269 - val_accuracy: 0.8080\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 8s 798us/step - loss: 0.3600 - accuracy: 0.8426 - val_loss: 0.4216 - val_accuracy: 0.8070\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 7s 740us/step - loss: 0.3545 - accuracy: 0.8450 - val_loss: 0.4296 - val_accuracy: 0.8100\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 7s 663us/step - loss: 0.3443 - accuracy: 0.8493 - val_loss: 0.4289 - val_accuracy: 0.8110\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 7s 707us/step - loss: 0.3391 - accuracy: 0.8527 - val_loss: 0.4247 - val_accuracy: 0.8180\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 6s 616us/step - loss: 0.3414 - accuracy: 0.8513 - val_loss: 0.4139 - val_accuracy: 0.8130\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 0.3409 - accuracy: 0.8465 - val_loss: 0.4402 - val_accuracy: 0.8160\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 7s 732us/step - loss: 0.3315 - accuracy: 0.8582 - val_loss: 0.4255 - val_accuracy: 0.8140\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 7s 721us/step - loss: 0.3323 - accuracy: 0.8535 - val_loss: 0.4264 - val_accuracy: 0.8140\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 6s 649us/step - loss: 0.3266 - accuracy: 0.8561 - val_loss: 0.4395 - val_accuracy: 0.8110\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 0.3272 - accuracy: 0.8544 - val_loss: 0.4283 - val_accuracy: 0.8150\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.3224 - accuracy: 0.8549 - val_loss: 0.4418 - val_accuracy: 0.8190\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 7s 693us/step - loss: 0.3189 - accuracy: 0.8611 - val_loss: 0.4302 - val_accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.3208 - accuracy: 0.8591 - val_loss: 0.4399 - val_accuracy: 0.8120\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 7s 699us/step - loss: 0.3132 - accuracy: 0.8648 - val_loss: 0.4448 - val_accuracy: 0.8160\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.3107 - accuracy: 0.8637 - val_loss: 0.4404 - val_accuracy: 0.8130\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 0.3120 - accuracy: 0.8639 - val_loss: 0.4501 - val_accuracy: 0.8200\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 0.3124 - accuracy: 0.8674 - val_loss: 0.4339 - val_accuracy: 0.8150\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 6s 639us/step - loss: 0.3076 - accuracy: 0.8697 - val_loss: 0.4510 - val_accuracy: 0.8100\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 6s 646us/step - loss: 0.3005 - accuracy: 0.8680 - val_loss: 0.4611 - val_accuracy: 0.8220\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 0.3022 - accuracy: 0.8707 - val_loss: 0.4330 - val_accuracy: 0.8180\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.3016 - accuracy: 0.8678 - val_loss: 0.4329 - val_accuracy: 0.8190\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 6s 642us/step - loss: 0.2977 - accuracy: 0.8695 - val_loss: 0.4470 - val_accuracy: 0.8210\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.2943 - accuracy: 0.8739 - val_loss: 0.4361 - val_accuracy: 0.8140\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.2961 - accuracy: 0.8752 - val_loss: 0.4483 - val_accuracy: 0.8210\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 6s 649us/step - loss: 0.2889 - accuracy: 0.8766 - val_loss: 0.4698 - val_accuracy: 0.8120\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 7s 703us/step - loss: 0.2884 - accuracy: 0.8774 - val_loss: 0.4557 - val_accuracy: 0.8180\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 7s 650us/step - loss: 0.2902 - accuracy: 0.8773 - val_loss: 0.4511 - val_accuracy: 0.8140\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 7s 670us/step - loss: 0.2848 - accuracy: 0.8773 - val_loss: 0.4639 - val_accuracy: 0.8260\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 8s 819us/step - loss: 0.2783 - accuracy: 0.8834 - val_loss: 0.4755 - val_accuracy: 0.8180\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 7s 663us/step - loss: 0.2768 - accuracy: 0.8786 - val_loss: 0.4584 - val_accuracy: 0.8210\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 7s 674us/step - loss: 0.2755 - accuracy: 0.8822 - val_loss: 0.4499 - val_accuracy: 0.8100\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 7s 663us/step - loss: 0.2758 - accuracy: 0.8828 - val_loss: 0.4557 - val_accuracy: 0.8180\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 7s 665us/step - loss: 0.2740 - accuracy: 0.8858 - val_loss: 0.4832 - val_accuracy: 0.8260\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 0.2748 - accuracy: 0.8790 - val_loss: 0.4724 - val_accuracy: 0.8160\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 6s 649us/step - loss: 0.2623 - accuracy: 0.8876 - val_loss: 0.4879 - val_accuracy: 0.8280\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 7s 666us/step - loss: 0.2666 - accuracy: 0.8850 - val_loss: 0.4986 - val_accuracy: 0.8140\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 7s 673us/step - loss: 0.2631 - accuracy: 0.8892 - val_loss: 0.4730 - val_accuracy: 0.8170\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 7s 660us/step - loss: 0.2633 - accuracy: 0.8860 - val_loss: 0.4991 - val_accuracy: 0.8140\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 7s 685us/step - loss: 0.2668 - accuracy: 0.8870 - val_loss: 0.4900 - val_accuracy: 0.8150\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit([inputs_train, queries_train], answers_train, batch_size=32, epochs=100, validation_data=([inputs_test, queries_test], answers_test))\n",
    "history = model.fit([inputs_train, queries_train], answers_train, batch_size=32, epochs=100, validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mybrandnewmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7614725e-12, 2.3202365e-12, 3.2541704e-12, 3.0887532e-12,\n",
       "       4.0994014e-12, 2.4114955e-12, 2.5425228e-12, 2.3164955e-12,\n",
       "       2.5370875e-12, 3.5268208e-12, 3.3300574e-12, 2.3435065e-12,\n",
       "       3.2333574e-12, 3.0584099e-12, 2.1303790e-12, 3.2292649e-12,\n",
       "       2.8092108e-12, 4.1594644e-12, 2.4275922e-12, 2.9781060e-12,\n",
       "       2.7997747e-12, 2.2223618e-12, 2.3088907e-12, 3.3373313e-12,\n",
       "       3.0313811e-12, 2.8326803e-12, 2.2156153e-12, 3.3610439e-12,\n",
       "       8.6337054e-01, 3.1478477e-12, 3.7097500e-12, 3.0745408e-12,\n",
       "       2.6740515e-12, 3.0878225e-12, 1.3662946e-01, 2.2973815e-12,\n",
       "       2.9453083e-12, 3.3977452e-12], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {index: word for word, index in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(pred_result, axis=1)\n",
    "pred_answers = [index_word[pred] for pred in predictions]\n",
    "pred_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a run time question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The answer should be 'yes'.\n",
    "mydata = [(my_story.split(), my_question.split(), 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model.predict([my_story, my_ques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer corresponding to the highest predict probabilty.\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988254"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out what's the highest predict probability.\n",
    "pred_result[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
